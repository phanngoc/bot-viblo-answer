{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/37kt02914kx36yzcbbqfyck00000gn/T/ipykernel_69039/950260037.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_ques = pd.read_sql(query, connection)\n",
      "/var/folders/g6/37kt02914kx36yzcbbqfyck00000gn/T/ipykernel_69039/950260037.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_answer = pd.read_sql(query_ans, connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['javascript']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import mysql.connector\n",
    "import json\n",
    "\n",
    "# Establish a connection to the MySQL database\n",
    "connection = mysql.connector.connect(\n",
    "    host='127.0.0.1',\n",
    "    port=13306,\n",
    "    user='root',\n",
    "    password='root',\n",
    "    database='pyml'\n",
    ")\n",
    "\n",
    "# Read the table data using pandas\n",
    "query = \"\"\"SELECT vi.hash_id, vi.contents as question_content, JSON_UNQUOTE(JSON_EXTRACT(tags, '$[*].slug')) AS slug FROM viblo_interview vi\"\"\"\n",
    "df_ques = pd.read_sql(query, connection)\n",
    "\n",
    "query_ans = \"\"\"SELECT va.hash_id, va.contents, va.question_id FROM viblo_answer va\"\"\"\n",
    "df_answer = pd.read_sql(query_ans, connection)\n",
    "\n",
    "# Close the database connection\n",
    "connection.close()\n",
    "\n",
    "\n",
    "def filter_slug(x):\n",
    "    if x is None:\n",
    "        return ''\n",
    "    t = str(x).replace(\"b'\", \"\").replace(\"'\", \"\")\n",
    "    t1 = json.loads(t)\n",
    "\n",
    "    return t1\n",
    "df_ques['slug_filter'] = df_ques['slug'].apply(filter_slug)\n",
    "print(df_ques['slug_filter'][0])\n",
    "\n",
    "# source = 'csv'\n",
    "\n",
    "# if source == 'csv':\n",
    "#     df_ques = pd.read_csv('./data/viblo_interview_202306161436.csv')\n",
    "    \n",
    "#     def filter_slug(t):\n",
    "#         if t is None:\n",
    "#             return ''\n",
    "#         t1 = json.loads(t)\n",
    "#         # get column name from list t1\n",
    "#         t2 = [x['name'] for x in t1]\n",
    "#         return t2\n",
    "\n",
    "#     df_ques['slug_filter'] = df_ques['tags'].apply(filter_slug)\n",
    "#     print(df_ques.head(5))\n",
    "#     df = df_ques[['id', 'contents', 'slug_filter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100          [java]\n",
      "101         [mysql]\n",
      "102          [java]\n",
      "103       [general]\n",
      "104          [java]\n",
      "105       [general]\n",
      "106       [general]\n",
      "107          [java]\n",
      "108    [javascript]\n",
      "109    [javascript]\n",
      "Name: slug_filter, dtype: object\n",
      "y_test [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "t [('java',)]\n",
      "class ['agile' 'ai' 'amazon-web-services' 'android-os' 'angularjs'\n",
      " 'artificial-intelligence' 'asp-net' 'attack-techniques' 'aws-lambda'\n",
      " 'backend-development' 'big-data' 'business-analyst' 'c' 'c-2' 'c-lang'\n",
      " 'chatbot' 'clean-code' 'cloud-computing' 'cloud-security'\n",
      " 'computer-network' 'computer-vision' 'content-creator' 'cryptography'\n",
      " 'css' 'cyber-security' 'dart' 'data-science'\n",
      " 'data-structures-and-algorithms' 'database' 'deep-learning'\n",
      " 'design-pattern' 'devops' 'distribute-system' 'docker'\n",
      " 'external-communication' 'flutter' 'forensics' 'freelancer'\n",
      " 'frontend-development' 'general' 'generative-models' 'git' 'golang'\n",
      " 'google-cloud-platform' 'html' 'image-classification'\n",
      " 'image-segmentation' 'infrastructure' 'internal-communication' 'ios'\n",
      " 'java' 'javascript' 'jquery' 'kubernetes' 'laravel' 'linux'\n",
      " 'malware-analysis' 'marketing' 'mathematics' 'ml' 'mlops'\n",
      " 'mobile-development' 'mobile-security' 'mysql' 'net' 'network-security'\n",
      " 'node-js' 'non-tech-job' 'nosql' 'nuxt-js' 'object-detection'\n",
      " 'object-oriented-programming' 'operating-system'\n",
      " 'optimization-algorithms' 'php' 'postgresql' 'programming'\n",
      " 'project-management' 'python' 'rails' 'react-js' 'react-native'\n",
      " 'recommendation-system' 'redis' 'reinforcement-learning'\n",
      " 'risk-management' 'ruby' 'secure-coding' 'security-management'\n",
      " 'security-tools' 'semi-supervised-learning' 'soft-skills'\n",
      " 'software-development' 'source-code' 'speech-processing' 'spring'\n",
      " 'spring-boot' 'sql' 'supervised-learning' 'swift' 'testing' 'typescript'\n",
      " 'unsupervised-learning' 'vue-js' 'vulnerability' 'web-development'\n",
      " 'web-security' 'windows' 'wordpress']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "Y = df_ques['slug_filter']\n",
    "print(Y[100:110])\n",
    "# Convert the input data to a binary array\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(Y)\n",
    "\n",
    "\n",
    "print('y_test', Y[100])\n",
    "t = mlb.inverse_transform(Y[100:101])\n",
    "print('t', t)\n",
    "print('class', mlb.classes_)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_ques['question_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import backend as K, initializers, regularizers, constraints, Model\n",
    "from keras.layers import Embedding, Flatten, MaxPooling1D, Dense, LSTM, Bidirectional, Attention, Layer, Input, Activation, Dropout, SpatialDropout1D\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing import sequence\n",
    "from gensim import corpora, models\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "w2v_model = KeyedVectors.load_word2vec_format('../model/wiki.vi.model.bin', binary=True)\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "maxlen = 100\n",
    "X_1 = sequence.pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "num_classes = Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2893, 100) (2893, 109)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_1, Y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words: 3497\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 100, 400)          1398800   \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 100, 128)         238080    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 109)               1395309   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,032,189\n",
      "Trainable params: 1,633,389\n",
      "Non-trainable params: 1,398,800\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "73/73 [==============================] - 6s 63ms/step - loss: 0.1025 - acc: 0.0549 - val_loss: 0.0514 - val_acc: 0.0777\n",
      "Epoch 2/10\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 0.0458 - acc: 0.1430 - val_loss: 0.0483 - val_acc: 0.0950\n",
      "Epoch 3/10\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 0.0391 - acc: 0.2835 - val_loss: 0.0454 - val_acc: 0.1796\n",
      "Epoch 4/10\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 0.0321 - acc: 0.4339 - val_loss: 0.0444 - val_acc: 0.1952\n",
      "Epoch 5/10\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 0.0259 - acc: 0.5644 - val_loss: 0.0441 - val_acc: 0.2159\n",
      "Epoch 6/10\n",
      "73/73 [==============================] - 4s 57ms/step - loss: 0.0209 - acc: 0.6651 - val_loss: 0.0436 - val_acc: 0.2487\n",
      "Epoch 7/10\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 0.0170 - acc: 0.7385 - val_loss: 0.0440 - val_acc: 0.2487\n",
      "Epoch 8/10\n",
      "73/73 [==============================] - 5s 65ms/step - loss: 0.0138 - acc: 0.7917 - val_loss: 0.0456 - val_acc: 0.2660\n",
      "Epoch 9/10\n",
      "73/73 [==============================] - 4s 61ms/step - loss: 0.0114 - acc: 0.8237 - val_loss: 0.0458 - val_acc: 0.2660\n",
      "Epoch 10/10\n",
      "73/73 [==============================] - 4s 59ms/step - loss: 0.0096 - acc: 0.8487 - val_loss: 0.0476 - val_acc: 0.2971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a5675570>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 400\n",
    "word_index = tokenizer.word_index\n",
    "num_words = min(len(word_index) + 1, len(w2v_model.index_to_key))\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "print('num_words:', num_words)\n",
    "for word, i in word_index.items():\n",
    "    if i >= num_words:\n",
    "        continue\n",
    "    if word in w2v_model.index_to_key:\n",
    "        embedding_matrix[i] = w2v_model.get_vector(word)\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=False))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True, input_shape=(maxlen, ))))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 19ms/step\n",
      "Y_pred (724, 109) (724, 109)\n",
      "Hamming Loss:  0.01\n",
      "F1-score:  0.28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss, f1_score\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "print('Y_pred', Y_pred.shape, Y_test.shape)\n",
    "\n",
    "max_indices = np.argmax(Y_pred, axis=1)\n",
    "# Convert the index to a binary array\n",
    "Y_pred_binary = np.eye(Y_pred.shape[1])[max_indices]\n",
    "# print('bin_arr', Y_pred_binary[0])\n",
    "print('Hamming Loss: ', round(hamming_loss(Y_test, Y_pred_binary),2))\n",
    "# Compute the F1-score\n",
    "f1_score = f1_score(Y_test, Y_pred_binary, average='micro')\n",
    "print('F1-score: ', round(f1_score, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 115ms/step\n",
      "res_pred 109\n",
      "max_indices [ 70  24  18  74 103  12  12  74  74  74  74  65  74  12  71 103]\n",
      "labels_pred ['object-detection', 'cyber-security', 'cloud-security', 'php', 'vue-js', 'c', 'c', 'php', 'php', 'php', 'php', 'network-security', 'php', 'c', 'object-oriented-programming', 'vue-js']\n",
      "Phân biệt mạng Object Detection 2 stage và 1 stage -> object-detection\n",
      "Những lỗ hổng thường gặp với API -> cyber-security\n",
      "IAM là gì, IAM có vai trò gì trong việc đảm bảo an toàn hệ thống AWS -> cloud-security\n",
      "Có bao nhiêu loại lỗi sai trong PHP? -> php\n",
      "Git Submodule trong trường hợp nào ? -> vue-js\n",
      "Có sự thừa kế theo cấp bậc giữa các module trong không? Giải thích. -> c\n",
      "Sự khác biệt giữa từ khóa break và continue trong Java? -> c\n",
      "Trình bày về Output Buffering trong PHP? -> php\n",
      "RESTful API là gì? -> php\n",
      "Viết tắt của php có nghĩa là gì ? -> php\n",
      "Phân biệt POST và GET trong php? -> php\n",
      "Cờ HttpOnly có tác dụng gì cho cookie? -> network-security\n",
      "so sánh sự khác nhau giữa Mysql và MongoDB -> php\n",
      "Tại sao phải sử dụng hàm khởi tạo? -> c\n",
      "Cơ chế hoạt động của API ? -> object-oriented-programming\n",
      "Sự khác nhau SOAP và REST APIs? -> vue-js\n"
     ]
    }
   ],
   "source": [
    "X_test = [\n",
    "    'Phân biệt mạng Object Detection 2 stage và 1 stage',\n",
    "    'Những lỗ hổng thường gặp với API',\n",
    "    'IAM là gì, IAM có vai trò gì trong việc đảm bảo an toàn hệ thống AWS',\n",
    "    'Có bao nhiêu loại lỗi sai trong PHP?',\n",
    "    'Git Submodule trong trường hợp nào ?',\n",
    "    'Có sự thừa kế theo cấp bậc giữa các module trong không? Giải thích.',\n",
    "    'Sự khác biệt giữa từ khóa break và continue trong Java?',\n",
    "    'Trình bày về Output Buffering trong PHP?',\n",
    "    'RESTful API là gì?',\n",
    "    'Viết tắt của php có nghĩa là gì ?',\n",
    "    'Phân biệt POST và GET trong php?',\n",
    "    'Cờ HttpOnly có tác dụng gì cho cookie?',\n",
    "    'so sánh sự khác nhau giữa Mysql và MongoDB',\n",
    "    'Tại sao phải sử dụng hàm khởi tạo?',\n",
    "    'Cơ chế hoạt động của API ?',\n",
    "    'Sự khác nhau SOAP và REST APIs?',\n",
    "]\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(X_test)\n",
    "maxlen = 100\n",
    "X_seq = sequence.pad_sequences(sequences, maxlen=maxlen)\n",
    "res_pred = model.predict(X_seq)\n",
    "print('res_pred', len(res_pred[1]))\n",
    "max_indices = np.argmax(res_pred, axis=1)\n",
    "print('max_indices', max_indices)\n",
    "\n",
    "labels_pred = list(map(lambda x: mlb.classes_[x], max_indices.tolist()))\n",
    "print('labels_pred', labels_pred)\n",
    "\n",
    "for index, tags in enumerate(labels_pred):\n",
    "    print(X_test[index][:100], '->', tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kết luận.\n",
    "- Model dùng word2vec pretrained (wiki.vi.model.bin) , giúp tính toán việc tạo tag khá ổn.\n",
    "- F1 score = 0.28, hơi thấp, nhưng do dữ liệu train còn ít (chỉ khoảng 3k câu) nên chưa thể đánh giá được."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
