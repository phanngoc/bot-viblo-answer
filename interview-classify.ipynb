{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/37kt02914kx36yzcbbqfyck00000gn/T/ipykernel_2117/950260037.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_ques = pd.read_sql(query, connection)\n",
      "/var/folders/g6/37kt02914kx36yzcbbqfyck00000gn/T/ipykernel_2117/950260037.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_answer = pd.read_sql(query_ans, connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['javascript']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import mysql.connector\n",
    "import json\n",
    "\n",
    "# Establish a connection to the MySQL database\n",
    "connection = mysql.connector.connect(\n",
    "    host='127.0.0.1',\n",
    "    port=13306,\n",
    "    user='root',\n",
    "    password='root',\n",
    "    database='pyml'\n",
    ")\n",
    "\n",
    "# Read the table data using pandas\n",
    "query = \"\"\"SELECT vi.hash_id, vi.contents as question_content, JSON_UNQUOTE(JSON_EXTRACT(tags, '$[*].slug')) AS slug FROM viblo_interview vi\"\"\"\n",
    "df_ques = pd.read_sql(query, connection)\n",
    "\n",
    "query_ans = \"\"\"SELECT va.hash_id, va.contents, va.question_id FROM viblo_answer va\"\"\"\n",
    "df_answer = pd.read_sql(query_ans, connection)\n",
    "\n",
    "# Close the database connection\n",
    "connection.close()\n",
    "\n",
    "\n",
    "def filter_slug(x):\n",
    "    if x is None:\n",
    "        return ''\n",
    "    t = str(x).replace(\"b'\", \"\").replace(\"'\", \"\")\n",
    "    t1 = json.loads(t)\n",
    "\n",
    "    return t1\n",
    "df_ques['slug_filter'] = df_ques['slug'].apply(filter_slug)\n",
    "print(df_ques['slug_filter'][0])\n",
    "\n",
    "# source = 'csv'\n",
    "\n",
    "# if source == 'csv':\n",
    "#     df_ques = pd.read_csv('./data/viblo_interview_202306161436.csv')\n",
    "    \n",
    "#     def filter_slug(t):\n",
    "#         if t is None:\n",
    "#             return ''\n",
    "#         t1 = json.loads(t)\n",
    "#         # get column name from list t1\n",
    "#         t2 = [x['name'] for x in t1]\n",
    "#         return t2\n",
    "\n",
    "#     df_ques['slug_filter'] = df_ques['tags'].apply(filter_slug)\n",
    "#     print(df_ques.head(5))\n",
    "#     df = df_ques[['id', 'contents', 'slug_filter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100          [java]\n",
      "101         [mysql]\n",
      "102          [java]\n",
      "103       [general]\n",
      "104          [java]\n",
      "105       [general]\n",
      "106       [general]\n",
      "107          [java]\n",
      "108    [javascript]\n",
      "109    [javascript]\n",
      "Name: slug_filter, dtype: object\n",
      "y_test [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "t [('java',)]\n",
      "class ['agile' 'ai' 'amazon-web-services' 'android-os' 'angularjs'\n",
      " 'artificial-intelligence' 'asp-net' 'attack-techniques' 'aws-lambda'\n",
      " 'backend-development' 'big-data' 'business-analyst' 'c' 'c-2' 'c-lang'\n",
      " 'chatbot' 'clean-code' 'cloud-computing' 'cloud-security'\n",
      " 'computer-network' 'computer-vision' 'content-creator' 'cryptography'\n",
      " 'css' 'cyber-security' 'dart' 'data-science'\n",
      " 'data-structures-and-algorithms' 'database' 'deep-learning'\n",
      " 'design-pattern' 'devops' 'distribute-system' 'docker'\n",
      " 'external-communication' 'flutter' 'forensics' 'freelancer'\n",
      " 'frontend-development' 'general' 'generative-models' 'git' 'golang'\n",
      " 'google-cloud-platform' 'html' 'image-classification'\n",
      " 'image-segmentation' 'infrastructure' 'internal-communication' 'ios'\n",
      " 'java' 'javascript' 'jquery' 'kubernetes' 'laravel' 'linux'\n",
      " 'malware-analysis' 'marketing' 'mathematics' 'ml' 'mlops'\n",
      " 'mobile-development' 'mobile-security' 'mysql' 'net' 'network-security'\n",
      " 'node-js' 'non-tech-job' 'nosql' 'nuxt-js' 'object-detection'\n",
      " 'object-oriented-programming' 'operating-system'\n",
      " 'optimization-algorithms' 'php' 'postgresql' 'programming'\n",
      " 'project-management' 'python' 'rails' 'react-js' 'react-native'\n",
      " 'recommendation-system' 'redis' 'reinforcement-learning'\n",
      " 'risk-management' 'ruby' 'secure-coding' 'security-management'\n",
      " 'security-tools' 'semi-supervised-learning' 'soft-skills'\n",
      " 'software-development' 'source-code' 'speech-processing' 'spring'\n",
      " 'spring-boot' 'sql' 'supervised-learning' 'swift' 'testing' 'typescript'\n",
      " 'unsupervised-learning' 'vue-js' 'vulnerability' 'web-development'\n",
      " 'web-security' 'windows' 'wordpress']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "Y = df_ques['slug_filter']\n",
    "print(Y[100:110])\n",
    "# Convert the input data to a binary array\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(Y)\n",
    "\n",
    "\n",
    "print('y_test', Y[100])\n",
    "t = mlb.inverse_transform(Y[100:101])\n",
    "print('t', t)\n",
    "print('class', mlb.classes_)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_ques['question_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words: 3497\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 400)          1398800   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 100, 128)         238080    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 109)               1395309   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,032,189\n",
      "Trainable params: 1,633,389\n",
      "Non-trainable params: 1,398,800\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "91/91 [==============================] - 8s 69ms/step - loss: 0.0871 - acc: 0.0546 - val_loss: 0.0782 - val_acc: 0.0083\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 6s 65ms/step - loss: 0.0428 - acc: 0.1849 - val_loss: 0.0765 - val_acc: 0.0180\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 7s 72ms/step - loss: 0.0354 - acc: 0.3477 - val_loss: 0.0768 - val_acc: 0.0773\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 6s 66ms/step - loss: 0.0283 - acc: 0.5033 - val_loss: 0.0771 - val_acc: 0.0594\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 5s 60ms/step - loss: 0.0223 - acc: 0.6367 - val_loss: 0.0815 - val_acc: 0.0622\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 6s 70ms/step - loss: 0.0181 - acc: 0.7079 - val_loss: 0.0857 - val_acc: 0.0815\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 6s 70ms/step - loss: 0.0145 - acc: 0.7674 - val_loss: 0.0927 - val_acc: 0.0746\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 7s 78ms/step - loss: 0.0123 - acc: 0.8113 - val_loss: 0.0934 - val_acc: 0.0718\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 7s 74ms/step - loss: 0.0102 - acc: 0.8368 - val_loss: 0.0957 - val_acc: 0.0953\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 6s 63ms/step - loss: 0.0088 - acc: 0.8617 - val_loss: 0.1007 - val_acc: 0.0704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2973a3400>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import backend as K, initializers, regularizers, constraints, Model\n",
    "from keras.layers import Embedding, Flatten, MaxPooling1D, Dense, LSTM, Bidirectional, Attention, Layer, Input, Activation, Dropout, SpatialDropout1D\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing import sequence\n",
    "from gensim import corpora, models\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "w2v_model = KeyedVectors.load_word2vec_format('../model/wiki.vi.model.bin', binary=True)\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "maxlen = 100\n",
    "X_train = sequence.pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "num_classes = Y.shape[1]\n",
    "\n",
    "embedding_dim = 400\n",
    "word_index = tokenizer.word_index\n",
    "num_words = min(len(word_index) + 1, len(w2v_model.index_to_key))\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "print('num_words:', num_words)\n",
    "for word, i in word_index.items():\n",
    "    if i >= num_words:\n",
    "        continue\n",
    "    if word in w2v_model.index_to_key:\n",
    "        embedding_matrix[i] = w2v_model.get_vector(word)\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=False))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True, input_shape=(maxlen, ))))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "model.fit(X_train, Y, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "res_pred 109\n",
      "max_indices [  5  24  82  74 103  71  50  74  74  74  74 108  74  71]\n",
      "labels_pred ['artificial-intelligence', 'cyber-security', 'recommendation-system', 'php', 'vue-js', 'object-oriented-programming', 'java', 'php', 'php', 'php', 'php', 'wordpress', 'php', 'object-oriented-programming']\n"
     ]
    }
   ],
   "source": [
    "X_test = [\n",
    "    'Phân biệt mạng Object Detection 2 stage và 1 stage',\n",
    "    'Những lỗ hổng thường gặp với API',\n",
    "    'IAM là gì, IAM có vai trò gì trong việc đảm bảo an toàn hệ thống AWS',\n",
    "    'Có bao nhiêu loại lỗi sai trong PHP?',\n",
    "    'Git Submodule trong trường hợp nào ?',\n",
    "    'Có sự thừa kế theo cấp bậc giữa các module trong không? Giải thích.',\n",
    "    'Sự khác biệt giữa từ khóa break và continue trong Java?',\n",
    "    'Trình bày về Output Buffering trong PHP?',\n",
    "    'RESTful API là gì?',\n",
    "    'Viết tắt của php có nghĩa là gì ?',\n",
    "    'Phân biệt POST và GET trong php?',\n",
    "    'Cờ HttpOnly có tác dụng gì cho cookie?',\n",
    "    'so sánh sự khác nhau giữa Mysql và MongoDB',\n",
    "    'Tại sao phải sử dụng hàm khởi tạo?',\n",
    "]\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(X_test)\n",
    "maxlen = 100\n",
    "X_seq = sequence.pad_sequences(sequences, maxlen=maxlen)\n",
    "res_pred = model.predict(X_seq)\n",
    "print('res_pred', len(res_pred[1]))\n",
    "max_indices = np.argmax(res_pred, axis=1)\n",
    "print('max_indices', max_indices)\n",
    "\n",
    "labels_pred = list(map(lambda x: mlb.classes_[x], max_indices.tolist()))\n",
    "print('labels_pred', labels_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
